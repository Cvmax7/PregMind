{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb9f98c",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# 一次微调\n",
    "# 基座模型：LLaMA3-8B-Chat，先采用 alpaca_gpt4_zh 数据集对 LLaMA3-8B-Chat 进行一次微调，提高中文对话能力\n",
    "\n",
    "# 配置: /mnt/workspace/Mindpilot/LLaMA-Factory/examples/train_lora/llama3_lora_sft.yaml\n",
    "# dataset: /mnt/workspace/Mindpilot/dataset/alpaca_gpt4_data_zh\n",
    "# 参数保存路径: /mnt/workspace/Mindpilot/saves/LLaMA3-8B-Chat/lora/sft_alpaca_v1\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 llamafactory-cli train /mnt/workspace/Mindpilot/LLaMA-Factory/examples/train_lora/llama3_lora_sft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b56e60",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# 一次微调模型导出\n",
    "\n",
    "# 模型路径: /mnt/workspace/Mindpilot/Meta-Llama-3-8B-Instruct\n",
    "# 参数保存路径: /mnt/workspace/Mindpilot/saves/LLaMA3-8B-Chat/lora/sft_alpaca_v1\n",
    "# 导出配置路径：/mnt/workspace/Mindpilot/LLaMA-Factory/examples/merge_lora/llama3_lora_sft.yaml\n",
    "# export_dir: /mnt/workspace/Mindpilot/output/Meta-Llama-3-8B-Instruct-alpaca_gpt4_zh-sfted_v1\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 llamafactory-cli export /mnt/workspace/Mindpilot/LLaMA-Factory/examples/merge_lora/llama3_lora_sft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b4837",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# 一次微调效果\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=0 llamafactory-cli chat /mnt/workspace/Mindpilot/LLaMA-Factory/examples/inference/llama3_lora_sft.yaml\n",
    "CUDA_VISIBLE_DEVICES=0 GRADIO_SHARE=1 llamafactory-cli webui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc059c33",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# 二次微调\n",
    "# 基座模型：Meta-Llama-3-8B-Instruct-alpaca_gpt4_zh-sfted_v1，采用 PsyQA 数据集对一次微调后的模型进行sft微调\n",
    "\n",
    "# 先将 psyQA_full_origin.json 数据集转换为适配的格式\n",
    "python /mnt/workspace/Mindpilot/dataset/data_process.py\n",
    "\n",
    "# 修改配置文件\n",
    "# 配置: /mnt/workspace/Mindpilot/LLaMA-Factory/examples/train_lora/llama3_lora_sft.yaml\n",
    "# 模型路径: /mnt/workspace/Mindpilot/output/Meta-Llama-3-8B-Instruct-alpaca_gpt4_zh-sfted_v1 \n",
    "# dataset: /mnt/workspace/Mindpilot/dataset/PsyQA\n",
    "# 参数保存路径：/mnt/workspace/Mindpilot/saves/LLaMA3-8B-Chat/lora/sft_psyQA_v2\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 llamafactory-cli train /mnt/workspace/Mindpilot/LLaMA-Factory/examples/train_lora/llama3_lora_sft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7bd4d4",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# 二次微调模型导出\n",
    "\n",
    "# 模型路径：/mnt/workspace/Mindpilot/output/Meta-Llama-3-8B-Instruct-alpaca_gpt4_zh-sfted_v1 \n",
    "# 参数保存路径：/mnt/workspace/Mindpilot/saves/LLaMA3-8B-Chat/lora/sft_psyQA_v2\n",
    "# 导出配置路径：/mnt/workspace/Mindpilot/LLaMA-Factory/examples/merge_lora/llama3_lora_sft.yaml\n",
    "# export_dir: /mnt/workspace/Mindpilot/output/Meta-Llama-3-8B-Instruct-psyQA-sfted_v2\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 llamafactory-cli export /mnt/workspace/Mindpilot/LLaMA-Factory/examples/merge_lora/llama3_lora_sft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e10c3",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# 二次微调效果\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=0 GRADIO_SHARE=1 llamafactory-cli webui\n",
    "CUDA_VISIBLE_DEVICES=0 llamafactory-cli chat /mnt/workspace/Mindpilot/LLaMA-Factory/examples/inference/llama3_lora_sft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c50b7",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# 训练奖励模型\n",
    "\n",
    "# 基座模型：Meta-Llama-3-8B-Instruct-psyQA-sfted_v2，以二次微调的模型作为基座\n",
    "# 数据集（已经加入偏好标注）：PsyQA_comparison.json\n",
    "# 配置：/mnt/workspace/Mindpilot/LLaMA-Factory/examples/train_lora/llama3_lora_reward.yaml\n",
    "# 模型路径：/mnt/workspace/Mindpilot/output/Meta-Llama-3-8B-Instruct-psyQA-sfted_v2\n",
    "# dataset: /mnt/workspace/Mindpilot/dataset/PsyQA_comparison\n",
    "# 参数保存路径：/mnt/workspace/Mindpilot/saves/LLaMA3-8B-Chat/lora/rm\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 llamafactory-cli train /mnt/workspace/Mindpilot/LLaMA-Factory/examples/train_lora/llama3_lora_reward.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095eddbd",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# PPO算法执行强化学习\n",
    "\n",
    "# 以二次微调的模型作为基座（Meta-Llama-3-8B-Instruct-psyQA-sfted_v2），加入奖励模型训练的参数（/mnt/workspace/Mindpilot/saves/LLaMA3-8B-Chat/lora/rm）\n",
    "# 数据集采用二次微调时的PsyQA.json\n",
    "\n",
    "# 强化学习配置：/mnt/workspace/Mindpilot/LLaMA-Factory/examples/train_lora/llama3_lora_ppo.yaml\n",
    "# 模型路径：/mnt/workspace/Mindpilot/output/Meta-Llama-3-8B-Instruct-psyQA-sfted_v2\n",
    "# 奖励模型参数路径：/mnt/workspace/Mindpilot/saves/LLaMA3-8B-Chat/lora/rm\n",
    "# dataset：/mnt/workspace/Mindpilot/dataset/PsyQA\n",
    "# 强化学习参数保存路径：/mnt/workspace/Mindpilot/saves/LLaMA3-8B-Chat/lora/ppo\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 llamafactory-cli train /mnt/workspace/Mindpilot/LLaMA-Factory/examples/train_lora/llama3_lora_ppo.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44b39b2",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# RLHF模型导出\n",
    "\n",
    "# 模型路径：/mnt/workspace/Mindpilot/output/Meta-Llama-3-8B-Instruct-psyQA-sfted_v2\n",
    "# 参数保存路径：/mnt/workspace/Mindpilot/saves/LLaMA3-8B-Chat/lora/ppo\n",
    "# 导出配置路径：/mnt/workspace/Mindpilot/LLaMA-Factory/examples/merge_lora/llama3_lora_sft.yaml\n",
    "# export_dir: /mnt/workspace/Mindpilot/output/Meta-Llama-3-8B-Instruct-psyQA-RLHG\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 llamafactory-cli export /mnt/workspace/Mindpilot/LLaMA-Factory/examples/merge_lora/llama3_lora_sft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c604969",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# 推理\n",
    "CUDA_VISIBLE_DEVICES=0 llamafactory-cli chat /mnt/workspace/Mindpilot/LLaMA-Factory/examples/inference/llama3_lora_sft.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
